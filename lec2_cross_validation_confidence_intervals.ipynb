{"cells":[{"cell_type":"markdown","id":"061143c6","metadata":{"id":"061143c6"},"source":["# Cross Validation and confidence intervals\n","In this notebook we will practice cross-validation."]},{"cell_type":"code","execution_count":6,"id":"97562303","metadata":{"id":"97562303"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import LeaveOneOut\n","from sklearn.model_selection import cross_val_predict\n","from sklearn.model_selection import KFold\n","from sklearn.utils import resample\n","from sklearn.metrics import r2_score"]},{"cell_type":"markdown","id":"IcXA6BrllVr8","metadata":{"id":"IcXA6BrllVr8"},"source":["## Data description\n","\n","1. Title: Auto-Mpg Data\n","\n","2. Sources:\n","   \n","   * Origin:  This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. The dataset was used in the 1983 American Statistical Association Exposition.\n","   * Date: July 7, 1993\n","\n","3. Past Usage:\n","    *  Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning.\n","       In Proceedings on the Tenth International Conference of Machine\n","       Learning, 236-243, University of Massachusetts, Amherst. Morgan\n","       Kaufmann.\n","\n","4. Relevant Information:\n","\n","   This dataset is a slightly modified version of the dataset provided in\n","   the StatLib library.  In line with the use by Ross Quinlan (1993) in\n","   predicting the attribute \"mpg\", 8 of the original instances were removed\n","   because they had unknown values for the \"mpg\" attribute.  The original\n","   dataset is available in the file \"auto-mpg.data-original\".\n","\n","   \"The data concerns city-cycle fuel consumption in miles per gallon,\n","    to be predicted in terms of 3 multivalued discrete and 5 continuous\n","    attributes.\" (Quinlan, 1993)\n","\n","5. Number of Instances:\n","\n","      \t398\n","\n","6. Number of Attributes: 9 including the class attribute\n","\n","7. Attribute Information:\n","\n","    * mpg:           continuous\n","    * cylinders:     multi-valued discrete\n","    * displacement:  continuous\n","    * horsepower:    continuous\n","    * weight:        continuous\n","    * acceleration:  continuous\n","    * model year:    multi-valued discrete\n","    * origin:        multi-valued discrete\n","    * car name:      string (unique for each instance)\n","\n","8. Missing Attribute Values:\n","\n","    * horsepower has 6 missing values\n","\n"]},{"cell_type":"markdown","id":"cbffac11","metadata":{"id":"cbffac11"},"source":["## Get data\n","\n","[Link to auto data](https://archive.ics.uci.edu/dataset/9/auto+mpg)"]},{"cell_type":"code","execution_count":7,"id":"8oKa8Vz3G4R-","metadata":{"id":"8oKa8Vz3G4R-"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ucimlrepo in /opt/homebrew/anaconda3/envs/ml/lib/python3.11/site-packages (0.0.3)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["# Run only once to unstall UCI ML Repo package.\n","%pip install ucimlrepo"]},{"cell_type":"code","execution_count":8,"id":"BQlFSx-UGbeO","metadata":{"id":"BQlFSx-UGbeO"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>displacement</th>\n","      <th>cylinders</th>\n","      <th>horsepower</th>\n","      <th>weight</th>\n","      <th>acceleration</th>\n","      <th>model_year</th>\n","      <th>origin</th>\n","      <th>mpg</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>307.0</td>\n","      <td>8</td>\n","      <td>130.0</td>\n","      <td>3504</td>\n","      <td>12.0</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>18.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>350.0</td>\n","      <td>8</td>\n","      <td>165.0</td>\n","      <td>3693</td>\n","      <td>11.5</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>15.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>318.0</td>\n","      <td>8</td>\n","      <td>150.0</td>\n","      <td>3436</td>\n","      <td>11.0</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>18.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>304.0</td>\n","      <td>8</td>\n","      <td>150.0</td>\n","      <td>3433</td>\n","      <td>12.0</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>16.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>302.0</td>\n","      <td>8</td>\n","      <td>140.0</td>\n","      <td>3449</td>\n","      <td>10.5</td>\n","      <td>70</td>\n","      <td>1</td>\n","      <td>17.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   displacement  cylinders  horsepower  weight  acceleration  model_year  \\\n","0         307.0          8       130.0    3504          12.0          70   \n","1         350.0          8       165.0    3693          11.5          70   \n","2         318.0          8       150.0    3436          11.0          70   \n","3         304.0          8       150.0    3433          12.0          70   \n","4         302.0          8       140.0    3449          10.5          70   \n","\n","   origin   mpg  \n","0       1  18.0  \n","1       1  15.0  \n","2       1  18.0  \n","3       1  16.0  \n","4       1  17.0  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["from ucimlrepo import fetch_ucirepo\n","\n","# fetch dataset\n","auto_mpg = fetch_ucirepo(id = 9)\n","\n","# data (as pandas dataframes)\n","auto = pd.concat([auto_mpg.data.features, auto_mpg.data.targets], axis = 1)\n","\n","auto.head()"]},{"cell_type":"code","execution_count":9,"id":"z1KvAUx8W0e9","metadata":{"id":"z1KvAUx8W0e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'uci_id': 9, 'name': 'Auto MPG', 'repository_url': 'https://archive.ics.uci.edu/dataset/9/auto+mpg', 'data_url': 'https://archive.ics.uci.edu/static/public/9/data.csv', 'abstract': 'Revised from CMU StatLib library, data concerns city-cycle fuel consumption', 'area': 'Other', 'tasks': ['Regression'], 'characteristics': ['Multivariate'], 'num_instances': 398, 'num_features': 7, 'feature_types': ['Real', 'Categorical', 'Integer'], 'demographics': [], 'target_col': ['mpg'], 'index_col': ['car_name'], 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1993, 'last_updated': 'Thu Aug 10 2023', 'dataset_doi': '10.24432/C5859H', 'creators': ['R. Quinlan'], 'intro_paper': None, 'additional_info': {'summary': 'This dataset is a slightly modified version of the dataset provided in the StatLib library.  In line with the use by Ross Quinlan (1993) in predicting the attribute \"mpg\", 8 of the original instances were removed because they had unknown values for the \"mpg\" attribute.  The original dataset is available in the file \"auto-mpg.data-original\".\\r\\n\\r\\n\"The data concerns city-cycle fuel consumption in miles per gallon, to be predicted in terms of 3 multivalued discrete and 5 continuous attributes.\" (Quinlan, 1993)', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '    1. mpg:           continuous\\r\\n    2. cylinders:     multi-valued discrete\\r\\n    3. displacement:  continuous\\r\\n    4. horsepower:    continuous\\r\\n    5. weight:        continuous\\r\\n    6. acceleration:  continuous\\r\\n    7. model year:    multi-valued discrete\\r\\n    8. origin:        multi-valued discrete\\r\\n    9. car name:      string (unique for each instance)', 'citation': None}}\n","           name     role         type demographic description units  \\\n","0  displacement  Feature   Continuous        None        None  None   \n","1           mpg   Target   Continuous        None        None  None   \n","2     cylinders  Feature      Integer        None        None  None   \n","3    horsepower  Feature   Continuous        None        None  None   \n","4        weight  Feature   Continuous        None        None  None   \n","5  acceleration  Feature   Continuous        None        None  None   \n","6    model_year  Feature      Integer        None        None  None   \n","7        origin  Feature      Integer        None        None  None   \n","8      car_name       ID  Categorical        None        None  None   \n","\n","  missing_values  \n","0             no  \n","1             no  \n","2             no  \n","3            yes  \n","4             no  \n","5             no  \n","6             no  \n","7             no  \n","8             no  \n"]}],"source":["# metadata\n","print(auto_mpg.metadata)\n","\n","# variable information\n","print(auto_mpg.variables)"]},{"cell_type":"code","execution_count":10,"id":"36d01b1a","metadata":{"id":"36d01b1a"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mpg</th>\n","      <th>horsepower</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>18.0</td>\n","      <td>130.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>15.0</td>\n","      <td>165.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>18.0</td>\n","      <td>150.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>16.0</td>\n","      <td>150.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>17.0</td>\n","      <td>140.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    mpg  horsepower\n","0  18.0       130.0\n","1  15.0       165.0\n","2  18.0       150.0\n","3  16.0       150.0\n","4  17.0       140.0"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["auto = auto[['mpg', 'horsepower']]\n","auto.head()"]},{"cell_type":"code","execution_count":null,"id":"c42f59dc","metadata":{"id":"c42f59dc"},"outputs":[],"source":["auto.shape"]},{"cell_type":"code","execution_count":null,"id":"ae0bbabc","metadata":{"id":"ae0bbabc"},"outputs":[],"source":["# we are dropping rows with NAs for this exercise\n","auto = auto.dropna()\n","auto.shape"]},{"cell_type":"markdown","id":"a0877592","metadata":{"id":"a0877592"},"source":["## Fit regression and polynomial regressions"]},{"cell_type":"code","execution_count":null,"id":"74ef5e8b","metadata":{"id":"74ef5e8b"},"outputs":[],"source":["auto = (\n","  auto.pipe(lambda p: p.assign(\n","    horsepower2 = p.horsepower**2,\n","    horsepower3 = p.horsepower**3\n","    )\n","  )\n",")"]},{"cell_type":"code","execution_count":null,"id":"3bddcfb4","metadata":{"id":"3bddcfb4"},"outputs":[],"source":["auto.head()"]},{"cell_type":"code","execution_count":null,"id":"fb069e54","metadata":{"id":"fb069e54"},"outputs":[],"source":["X = auto.iloc[:, 1:]\n","Y = auto.mpg"]},{"cell_type":"code","execution_count":null,"id":"7b411dac","metadata":{"id":"7b411dac"},"outputs":[],"source":["def scale_train_test(x: np.array,\n","                     y: np.array,\n","                     test_size: float = 0.2,\n","                     random_state: int = 86675309) -> tuple:\n","  \"\"\"Split data into train/test and scale using a standard scaler.\n","\n","  Arguments:\n","    x (np.array): (n, p) array of features.\n","    y (np.array): (n, ) array of targets.\n","    test_size (float): Size of test data (default: 0.2).\n","    random_state (int): Seed used in random split (default: 8675309).\n","\n","  Returns:\n","    A tuple containing:\n","      x_train_scaled: np.array of size (n * (1 - test_size), p)\n","      x_test_scaled: np.array of size (n * test_size, p)\n","      y_train: np.array of size (n * (1 - test_size), )\n","      y_test: np.array of size (n * test_size, )\n","  \"\"\"\n","\n","  # Split data into train/test.\n","  x_train, x_test, y_train, y_test = train_test_split(\n","      x, y, test_size = test_size, random_state = random_state)\n","\n","  # Creates the scaler.\n","  scaler = StandardScaler()\n","  scaler.fit(x_train)\n","\n","  # Scale training data.\n","  x_train_scaled = scaler.transform(x_train)\n","  # Scale test data.\n","  x_test_scaled = scaler.transform(x_test)\n","\n","  return x_train_scaled, x_test_scaled, y_train, y_test\n","\n","X_train, X_test, y_train, y_test = scale_train_test(X, Y)"]},{"cell_type":"markdown","id":"Ybkh2Uyxlb91","metadata":{"id":"Ybkh2Uyxlb91"},"source":["Fit regression with $\\tt{mpg} \\sim \\tt{horsepower}$"]},{"cell_type":"code","execution_count":null,"id":"397c5b4b","metadata":{"id":"397c5b4b"},"outputs":[],"source":["reg = LinearRegression().fit(X_train[:, 0].reshape(-1, 1), y_train)\n","\n","# training and test scores\n","r2_train = reg.score(X_train[:, 0].reshape(-1, 1),  y_train)\n","r2_test = reg.score(X_test[:, 0].reshape(-1, 1),  y_test)\n","\n","r2_train, r2_test"]},{"cell_type":"code","execution_count":null,"id":"5H6PsMpto9lg","metadata":{"id":"5H6PsMpto9lg"},"outputs":[],"source":["reg.coef_"]},{"cell_type":"code","execution_count":null,"id":"00e4cf54","metadata":{"id":"00e4cf54"},"outputs":[],"source":["sns.regplot(x=X_train[:, 0], y=y_train, ci=None, scatter_kws={'alpha':0.3})\n","sns.scatterplot(x=X_test[:, 0], y=y_test, color=\"green\") # test set in green"]},{"cell_type":"markdown","id":"Bco7hCynk5MG","metadata":{"id":"Bco7hCynk5MG"},"source":["Fit regression with $\\tt{mpg} \\sim \\tt{horsepower} + \\tt{horsepower}^2$"]},{"cell_type":"code","execution_count":null,"id":"4e40ea4e","metadata":{"id":"4e40ea4e"},"outputs":[],"source":["reg2 = LinearRegression().fit(X_train[:, 0:2], y_train)\n","\n","# training and test scores\n","r2_train = reg2.score(X_train[:, 0:2],  y_train)\n","r2_test = reg2.score(X_test[:, 0:2],  y_test)\n","\n","r2_train, r2_test"]},{"cell_type":"code","execution_count":null,"id":"URwRxceLtHDf","metadata":{"id":"URwRxceLtHDf"},"outputs":[],"source":["reg2.coef_"]},{"cell_type":"markdown","id":"1X9xHMD6lKrQ","metadata":{"id":"1X9xHMD6lKrQ"},"source":["Fit regression with $\\tt{mpg} \\sim \\tt{horsepower} + \\tt{horsepower}^2 + \\tt{horsepower}^3$"]},{"cell_type":"code","execution_count":null,"id":"f25b5978","metadata":{"id":"f25b5978"},"outputs":[],"source":["reg3 = LinearRegression().fit(X_train, y_train)\n","\n","# training and test scores\n","r2_train = reg3.score(X_train,  y_train)\n","r2_test = reg3.score(X_test,  y_test)\n","\n","r2_train, r2_test"]},{"cell_type":"code","execution_count":null,"id":"7pKm3s3atI3e","metadata":{"id":"7pKm3s3atI3e"},"outputs":[],"source":["reg3.coef_"]},{"cell_type":"markdown","id":"c9293e73","metadata":{"id":"c9293e73"},"source":["## Leave-One-Out Cross-Validation"]},{"cell_type":"markdown","id":"600e071f","metadata":{"id":"600e071f"},"source":["### without scaling"]},{"cell_type":"code","execution_count":null,"id":"bcda3b8f","metadata":{"id":"bcda3b8f"},"outputs":[],"source":["cv = LeaveOneOut()\n","# note that we are not doing scaling here\n","y_pred = cross_val_predict(reg, X, Y, cv=cv)"]},{"cell_type":"code","execution_count":null,"id":"81695bcb","metadata":{"id":"81695bcb"},"outputs":[],"source":["r2_score(Y, y_pred)"]},{"cell_type":"markdown","id":"6bee2532","metadata":{"id":"6bee2532"},"source":["### with scaling"]},{"cell_type":"code","execution_count":null,"id":"c38ed789","metadata":{"id":"c38ed789"},"outputs":[],"source":["# with scaling\n","kf = KFold(n_splits = Y.shape[0])\n","kf.get_n_splits(X)"]},{"cell_type":"code","execution_count":null,"id":"9ba0d849","metadata":{"id":"9ba0d849"},"outputs":[],"source":["pred = []\n","for train_index, test_index in kf.split(X):\n","  X_train, X_test = X.values[train_index], X.values[test_index]\n","  y_train = Y.values[train_index]\n","  scaler = StandardScaler() # creates the scaler\n","  scaler.fit(X_train)\n","  X_train = scaler.transform(X_train)\n","  X_test = scaler.transform(X_test)\n","  reg = LinearRegression().fit(X_train, y_train)\n","  pred.append(reg.predict(X_test))"]},{"cell_type":"code","execution_count":null,"id":"0fc4ac9b","metadata":{"id":"0fc4ac9b"},"outputs":[],"source":["r2_score(Y, pred)"]},{"cell_type":"markdown","id":"20936783","metadata":{"id":"20936783"},"source":["## K fold cross-validation"]},{"cell_type":"code","execution_count":null,"id":"0aaf0295","metadata":{"id":"0aaf0295"},"outputs":[],"source":["# with scaling\n","kf = KFold(n_splits = 10, random_state = 8675309, shuffle = True)\n","kf.get_n_splits(X)"]},{"cell_type":"code","execution_count":null,"id":"7b96b7eb","metadata":{"id":"7b96b7eb"},"outputs":[],"source":["r2s = []\n","for train_index, test_index in kf.split(X):\n","  X_train, X_test = X.values[train_index], X.values[test_index]\n","  y_train, y_test = Y.values[train_index], Y.values[test_index]\n","  scaler = StandardScaler() # creates the scaler\n","  scaler.fit(X_train)\n","  X_train = scaler.transform(X_train)\n","  X_test = scaler.transform(X_test)\n","  reg = LinearRegression().fit(X_train, y_train)\n","  y_test_hat = reg.predict(X_test)\n","  r2 = r2_score(y_test, y_test_hat)\n","  r2s.append(r2)"]},{"cell_type":"code","execution_count":null,"id":"ecda7c7d","metadata":{"id":"ecda7c7d"},"outputs":[],"source":["np.mean(r2s)"]},{"cell_type":"markdown","id":"8a72519d","metadata":{"id":"8a72519d"},"source":["## Regularized regression (L2)\n","\n","RidgeCV automatically finds the best hyper\n","parameters for ridge regularized logistic regression (L2). In this case the only parameter is the regularization strength."]},{"cell_type":"code","execution_count":null,"id":"86b25725","metadata":{"id":"86b25725"},"outputs":[],"source":["from sklearn.linear_model import RidgeCV\n","from sklearn.linear_model import Ridge"]},{"cell_type":"markdown","id":"d05bc8a2","metadata":{"id":"d05bc8a2"},"source":["### wrong way: without scaling"]},{"cell_type":"code","execution_count":null,"id":"f7411484","metadata":{"id":"f7411484"},"outputs":[],"source":["X = auto.iloc[:, 1:].values # ignore 0th column\n","Y = auto.iloc[:, 0].values\n","X.shape, Y.shape"]},{"cell_type":"code","execution_count":null,"id":"9296afad","metadata":{"id":"9296afad"},"outputs":[],"source":["x_train, x_test, y_train, y_test = train_test_split(\n","    X, Y, test_size=0.2, random_state=8675309)\n","# cross-validation with the training set\n","ridge = RidgeCV(cv=10).fit(x_train, y_train)"]},{"cell_type":"code","execution_count":null,"id":"aca89cc8","metadata":{"id":"aca89cc8"},"outputs":[],"source":["ridge.alpha_"]},{"cell_type":"code","execution_count":null,"id":"ed73b49e","metadata":{"id":"ed73b49e"},"outputs":[],"source":["ridge.score(x_test, y_test)"]},{"cell_type":"markdown","id":"00491a0b","metadata":{"id":"00491a0b"},"source":["### with scaling"]},{"cell_type":"code","execution_count":null,"id":"cd7c872d","metadata":{"id":"cd7c872d"},"outputs":[],"source":["scaler = StandardScaler() # creates the scaler\n","scaler.fit(x_train)\n","X_train = scaler.transform(x_train)\n","X_test = scaler.transform(x_test)"]},{"cell_type":"code","execution_count":null,"id":"80c18c57","metadata":{"id":"80c18c57"},"outputs":[],"source":["ridge = RidgeCV(cv=10).fit(X_train, y_train)\n","ridge.alpha_"]},{"cell_type":"code","execution_count":null,"id":"ba0b2b35","metadata":{"id":"ba0b2b35"},"outputs":[],"source":["ridge.score(X_test, y_test)"]},{"cell_type":"code","execution_count":null,"id":"23cef2ad","metadata":{"id":"23cef2ad"},"outputs":[],"source":["ridge = Ridge(alpha=1).fit(X_train, y_train)\n","ridge.score(X_test, y_test)"]},{"cell_type":"markdown","id":"dfee9371","metadata":{"id":"dfee9371"},"source":["This is still not perfect. Why?"]},{"cell_type":"markdown","id":"fba4f8ab","metadata":{"id":"fba4f8ab"},"source":["### Better but more complicated"]},{"cell_type":"code","execution_count":null,"id":"d62e1fed","metadata":{"id":"d62e1fed"},"outputs":[],"source":["def score_given_alpha(x: np.array,\n","                      y: np.array,\n","                      kfold: KFold,\n","                      alpha: float) -> float:\n","  \"\"\"Run a ridge regression with k-fold cross validation and a given penalty\n","  term (alpha).\n","\n","  Arguments:\n","    x (np.array): An array with shape (n, p) containing the attributes.\n","    y (np.array): An array with shape (n, ) containing the targets.\n","    kfold (KFold): An object of class KFold.\n","    alpha (float): The penalty term in the ridge regression.\n","\n","  Returns:\n","    The average R^2 (test) across the k-folds.\n","  \"\"\"\n","\n","  # Storage for the R^2 values.\n","  r2s = []\n","\n","  # Loop over the k-folds.\n","  for train_index, test_index in kfold.split(x):\n","    # Split the data between training and test\n","    x_train, x_test = x[train_index], x[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","\n","    # Create the scaler using the training data.\n","    scaler = StandardScaler()\n","    scaler.fit(x_train)\n","\n","    # Scale the train/test data.\n","    X_train = scaler.transform(x_train)\n","    X_test = scaler.transform(x_test)\n","\n","    # Run ridge regression with a given alpha.\n","    reg = Ridge(alpha=alpha).fit(X_train, y_train)\n","\n","    # Predict on test and determine R^2 (test).\n","    # Alternatively, you can use:\n","    #   r2 = reg.score(X_test, y_test)]\n","    y_test_hat = reg.predict(X_test)\n","    r2 = r2_score(y_test, y_test_hat)\n","    r2s.append(r2)\n","\n","  # Return the mean R^2 across all the folds.\n","  return np.mean(r2s)"]},{"cell_type":"code","execution_count":null,"id":"e280dff3","metadata":{"id":"e280dff3"},"outputs":[],"source":["def find_best_score(x: np.array,\n","                    y: np.array,\n","                    n_splits: int = 10,\n","                    random_state: int = 8675309,\n","                    alphas: np.array = [0.001, 0.01, 0.1, 1, 10, 100]) -> tuple:\n","  \"\"\"Find the best alpha in a ridge regression.\n","\n","  Arguments:\n","    x (np.array): An array with shape (n, p) containing the attributes.\n","    y (np.array): An array with shape (n, ) containing the targets.\n","    n_splits (int): The number of folds in the k-fold (default: 10).\n","    random_state (int): The seed to use in the cv (default: 8675309).\n","    alpha (np.array): The penalty term in the ridge regression (default:\n","      [0.001, 0.01, 0.1, 1, 10, 100]).\n","\n","  \"\"\"\n","\n","  # Initial states for best_alpha and best_score.\n","  best_alpha = alphas[0]\n","  best_score = 0\n","\n","  # Create KFold splitss.\n","  kf = KFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n","  kf.get_n_splits(x_train)\n","\n","  # Loop over the alphas.\n","  for alpha in alphas:\n","    # Determine the R^2 (test) for the current alpha.\n","    score = score_given_alpha(x, y, kf, alpha)\n","\n","    # If new score is better than current score, then update the values.\n","    if score > best_score:\n","      best_score = score\n","      best_alpha = alpha\n","\n","  # Return the best_score and best_alpha from the loop.\n","  return best_score, best_alpha"]},{"cell_type":"code","execution_count":null,"id":"4fc4871c","metadata":{"id":"4fc4871c"},"outputs":[],"source":["best_score, best_alpha = find_best_score(x_train, y_train)\n","best_score, best_alpha"]},{"cell_type":"code","execution_count":null,"id":"24c5afff","metadata":{"id":"24c5afff"},"outputs":[],"source":["ridge = Ridge(alpha = best_alpha).fit(X_train, y_train)\n","ridge.score(X_test, y_test)"]},{"cell_type":"code","execution_count":null,"id":"1dZLcwtgtTDo","metadata":{"id":"1dZLcwtgtTDo"},"outputs":[],"source":["ridge.coef_"]},{"cell_type":"code","execution_count":null,"id":"Ro6hQqUztd6H","metadata":{"id":"Ro6hQqUztd6H"},"outputs":[],"source":["def plot_ridge(x: np.array,\n","               y: np.array,\n","               ridge: Ridge,\n","               point_color: str = 'darkgray',\n","               point_alpha: float = 0.8,\n","               line_color: str = 'steelblue',\n","               xlab: str = 'horsepower',\n","               ylab: str = 'mpg') -> None:\n","  \"\"\"Plot the observed values and fitted line from a ridge regression.\n","\n","  Arguments:\n","    x (np.array): Array of shape (n, p). The first column will contain\n","      'horsepower'.\n","    y (np.array): Array of shape (n, ).\n","    ridge (Ridge): The ridge regression fitted on training data.\n","    point_color (str): Color of the points (default: 'darkgray').\n","    point_alpha (float): Alpha value of the points (default: 0.8).\n","    line_color (str): Color of fitted line.\n","    xlab (str): Label for the x-axis (default: 'horsepower').\n","    ylab (str): Label for the y-axis (default: 'mpg'):\n","\n","  Returns: Nothing\n","  \"\"\"\n","\n","  # Add observe values to a scatter plot.\n","  sns.scatterplot(x=x[:, 0], y=y, color=point_color, alpha=point_alpha)\n","\n","  # Add predicted line.\n","  sns.lineplot(x=x[:, 0], y=ridge.predict(x), color=line_color, linewidth=2)\n","\n","  # Add x- and y-axes labels.\n","  plt.xlabel(xlab)\n","  plt.ylabel(ylab)\n","\n","plot_ridge(X_test, y_test, ridge)"]},{"cell_type":"markdown","id":"46aaef8f","metadata":{"id":"46aaef8f"},"source":["## Confidence interval for test $R^2$ with repeated experiments"]},{"cell_type":"code","execution_count":null,"id":"fe1cbf1a","metadata":{"id":"fe1cbf1a"},"outputs":[],"source":["scores = []\n","for i in range(50):\n","  # Split the data into train/test using a new seed for each iteration.\n","  x_train, x_test, y_train, y_test = train_test_split(\n","      X, Y, test_size=0.2, random_state=i)\n","\n","  # We drop the R^2 since this we're only determining alpha with the training.\n","  _, alpha = find_best_score(x_train, y_train, random_state = i)\n","\n","  # Make the scaler in this loop.\n","  scaler = StandardScaler()\n","  scaler.fit(x_train)\n","\n","  # Scale training and test.\n","  X_train = scaler.transform(x_train)\n","  X_test = scaler.transform(x_test)\n","\n","  # Fit ridge regression with the best alpha and store the R^2 (test).\n","  ridge = Ridge(alpha=alpha).fit(X_train, y_train)\n","  scores.append(ridge.score(X_test, y_test))"]},{"cell_type":"code","execution_count":null,"id":"3887c0e8","metadata":{"id":"3887c0e8","scrolled":true},"outputs":[],"source":["np.array(scores)"]},{"cell_type":"code","execution_count":null,"id":"de441b69","metadata":{"id":"de441b69"},"outputs":[],"source":["np.quantile(scores, q = 0.025), np.quantile(scores, q = 0.975)"]},{"cell_type":"markdown","id":"55887f4d","metadata":{"id":"55887f4d"},"source":["## Lab:\n","Consider a model that predicts *mpg* as a function of a polynomial regression of degree 6 of *horsepower*. Use Lasso (L1 penalty) to fit the best model. Use cross-validation to find the best regularization parameter.\n","\n","* What is the final formula and plot the results?\n","* Which are the non-zero coefficients?\n","* Give an assesment of the $R^2$ value with an interpretation and confidence intervals.\n","* Suppose you are trying to find the best degree polynomial. What would you do differently if you were using ridge regression?"]},{"cell_type":"markdown","id":"x9fyc1CBVNPo","metadata":{"id":"x9fyc1CBVNPo"},"source":["## statsmodels.api\n","\n","When doing simple analysis with linear regression, the statsmodels package has a nicer (more R-like) interface. It also gives a more readable summary of the output."]},{"cell_type":"code","execution_count":null,"id":"072d76bf","metadata":{"id":"072d76bf"},"outputs":[],"source":["import statsmodels.api as sm\n","import statsmodels.formula.api as smf\n","\n","auto_lm = smf.glm(\n","    formula = 'mpg ~ horsepower + I(horsepower**2)',\n","    data = auto,\n","    family = sm.families.Gaussian()).fit()\n","\n","print(auto_lm.summary())"]},{"cell_type":"code","execution_count":null,"id":"WPAsjvsa2j4q","metadata":{"id":"WPAsjvsa2j4q"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}
